# ML Model Performans Ä°yileÅŸtirme Rehberi

## ğŸ“Š Mevcut Durum Analizi

### Model PerformanslarÄ±:
- **LightGBM Classifier**: 64.09% accuracy âœ… (Ä°yi)
  - BUY F1: 67.43%
  - SELL F1: 70.31%
  - HOLD: HiÃ§ tahmin edilmiyor âŒ

- **XGBoost Regressor**: RÂ²=0.18, Direction Accuracy=70.24% âœ… (OldukÃ§a Ä°yi!)
  - MAE: 24.23
  - RMSE: 40.93
  - Direction prediction Ã§ok iyi!

- **LSTM Model**: 43.59% accuracy âŒ (Ã‡ok ZayÄ±f)
  - Sadece BUY tahmin ediyor
  - Class imbalance sorunu
  - Epoch 32'de early stopping

- **Ensemble Meta-Learner**: 63.86% accuracy âœ… (Ä°yi)
  - BUY F1: 67.84%
  - SELL F1: 69.45%
  - Production'da aktif

---

## ğŸ¯ Ä°yileÅŸtirme Stratejileri

### 1ï¸âƒ£ LSTM Model Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: YÃœKSEK) âš ï¸

#### Sorunlar:
- Sadece BUY sÄ±nÄ±fÄ±nÄ± tahmin ediyor (confusion matrix'e gÃ¶re)
- Class imbalance problemi var
- Early stopping Ã§ok erken durmuÅŸ (32 epoch)
- Validation loss iyileÅŸmiyor

#### Ã‡Ã¶zÃ¼mler:

**A) Class Weighting Ekle**
```python
# backend/ml/models/lstm_model.py iÃ§inde

# Loss fonksiyonuna class weights ekle
class_weights = torch.tensor([1.5, 2.0, 1.0])  # SELL, HOLD, BUY
criterion = nn.CrossEntropyLoss(weight=class_weights)

# Veya balanced sampling kullan
from torch.utils.data import WeightedRandomSampler
```

**B) Architecture Ä°yileÅŸtirme**
```python
# Bidirectional LSTM ekle
self.lstm = nn.LSTM(
    input_size,
    hidden_size,
    num_layers,
    dropout=dropout,
    bidirectional=True,  # â† Ekle
    batch_first=True
)

# Attention mechanism ekle
class Attention(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.attention = nn.Linear(hidden_size * 2, 1)

    def forward(self, lstm_output):
        attention_weights = F.softmax(self.attention(lstm_output), dim=1)
        context = torch.sum(attention_weights * lstm_output, dim=1)
        return context
```

**C) Sequence Length ArtÄ±r**
```python
# train_ml.py iÃ§inde
X_train_seq, y_train_seq = dataset.create_sequences(
    data['X_train'], data['y_train'],
    sequence_length=100  # 50 â†’ 100 yap
)
```

**D) Training Ä°yileÅŸtirmeleri**
```python
# Learning rate scheduler ekle
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5
)

# Batch normalization
self.batch_norm = nn.BatchNorm1d(hidden_size * 2)

# Early stopping patience artÄ±r
early_stopping_patience=20  # 10 â†’ 20
```

**E) Data Augmentation**
```python
# Time series augmentation
def add_noise(X, noise_level=0.01):
    noise = np.random.normal(0, noise_level, X.shape)
    return X + noise

def scale_amplitude(X, sigma=0.1):
    scaling_factor = np.random.normal(1.0, sigma, (X.shape[0], 1, X.shape[2]))
    return X * scaling_factor
```

---

### 2ï¸âƒ£ Label Engineering Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: YÃœKSEK) ğŸ¯

#### Sorunlar:
- `threshold=0.002` (%0.2) Ã§ok kÃ¼Ã§Ã¼k kripto iÃ§in
- HOLD sÄ±nÄ±fÄ± Ã§ok fazla, BUY/SELL az
- Tek horizon (5 saat) yetersiz

#### Ã‡Ã¶zÃ¼mler:

**A) Threshold'u ArtÄ±r**
```python
# backend/ml/data/labels.py iÃ§inde create_direction_label()

def create_direction_label(self, periods=5, threshold=0.005):  # 0.002 â†’ 0.005
    """
    3-class classification: SELL (0), HOLD (1), BUY (2)

    Args:
        periods: Future periods to look ahead
        threshold: Minimum % change to classify as BUY/SELL
            - 0.5% daha gerÃ§ekÃ§i kripto iÃ§in
            - Daha az HOLD, daha fazla actionable signals
    """
    future_return = (self.df['close'].shift(-periods) - self.df['close']) / self.df['close']

    self.df['label_direction'] = np.select(
        [future_return < -threshold, future_return > threshold],
        [0, 2],  # SELL, BUY
        default=1  # HOLD
    )

    return self.df
```

**B) Adaptive (Volatility-Based) Threshold**
```python
def create_adaptive_direction_label(self, periods=5, volatility_multiplier=2):
    """
    Volatility-based dynamic thresholding
    YÃ¼ksek volatilitede threshold bÃ¼yÃ¼r, dÃ¼ÅŸÃ¼kte kÃ¼Ã§Ã¼lÃ¼r
    """
    future_return = (self.df['close'].shift(-periods) - self.df['close']) / self.df['close']

    # 20-period rolling volatility
    rolling_vol = self.df['close'].pct_change().rolling(20).std()

    # Dynamic threshold: 2x volatility
    dynamic_threshold = rolling_vol * volatility_multiplier

    self.df['label_direction'] = np.select(
        [
            future_return < -dynamic_threshold,
            future_return > dynamic_threshold
        ],
        [0, 2],  # SELL, BUY
        default=1  # HOLD
    )

    return self.df
```

**C) Multi-Horizon Labels**
```python
def create_multi_horizon_labels(self):
    """
    FarklÄ± zaman dilimlerinde tahmin
    1h, 4h, 1d sonrasÄ±nÄ± birleÅŸtir
    """
    # Short-term (1h)
    self.df['label_1h'] = self._direction_label(periods=1, threshold=0.003)

    # Medium-term (4h)
    self.df['label_4h'] = self._direction_label(periods=4, threshold=0.005)

    # Long-term (24h)
    self.df['label_24h'] = self._direction_label(periods=24, threshold=0.01)

    # Consensus: En az 2/3 aynÄ± direction
    labels = self.df[['label_1h', 'label_4h', 'label_24h']]
    self.df['label_consensus'] = labels.mode(axis=1)[0]

    return self.df
```

**D) Risk-Adjusted Labels**
```python
def create_risk_reward_label(self, periods=5, risk_reward_ratio=2.0):
    """
    Sadece risk/reward ratio iyi olan trade'leri BUY/SELL yap
    DiÄŸerleri HOLD
    """
    future_high = self.df['high'].rolling(periods).max().shift(-periods)
    future_low = self.df['low'].rolling(periods).min().shift(-periods)
    current = self.df['close']

    potential_profit = (future_high - current) / current
    potential_loss = (current - future_low) / current

    # Risk/Reward ratio check
    good_buy = (potential_profit / (potential_loss + 1e-10)) > risk_reward_ratio
    good_sell = (potential_loss / (potential_profit + 1e-10)) > risk_reward_ratio

    self.df['label_direction'] = np.select(
        [good_sell, good_buy],
        [0, 2],  # SELL, BUY
        default=1  # HOLD (risky trades)
    )

    return self.df
```

---

### 3ï¸âƒ£ Hyperparameter Optimization (Ã–NCELÄ°K: ORTA) ğŸ”§

#### Åu Anki Durum:
`optimize_hyperparams=False` â†’ Default parametreler kullanÄ±lÄ±yor

#### YapÄ±lacak:

**A) Train Script'i GÃ¼ncelle**
```python
# backend/train_ml.py - main() fonksiyonu

async def main():
    """Main entry point"""
    pipeline = MLTrainingPipeline(
        symbols=['BTCUSDT', 'ETHUSDT', 'BNBUSDT'],
        interval='1h',
        future_periods=5,
        optimize_hyperparams=True,  # â† BUNU AÃ‡ (False â†’ True)
        train_ensemble=True
    )

    await pipeline.run()
```

**B) Optimization Parameters Ayarla**
```python
# backend/ml/training/hyperopt.py iÃ§inde

# n_trials artÄ±r (daha fazla deneme = daha iyi sonuÃ§)
optimizer = HyperparameterOptimizer(
    n_trials=100,  # 50 â†’ 100
    timeout=7200   # 1 saat â†’ 2 saat
)
```

**Beklenen Ä°yileÅŸme:**
- **LightGBM**: +2-5% accuracy (66-69%)
- **XGBoost**: +0.02-0.05 RÂ² (0.20-0.23)
- **LSTM**: +5-10% accuracy (48-53%)

---

### 4ï¸âƒ£ Feature Engineering Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: YÃœKSEK) ğŸ“Š

#### A) Market Microstructure Features

```python
# backend/features/advanced_indicators.py'ye ekle

class MarketMicrostructure:
    """
    Advanced market microstructure features
    """

    @staticmethod
    def add_funding_rate_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        Funding rate (futures market)
        Binance API'den Ã§ek
        """
        # API call to get funding rate history
        # df['funding_rate'] = ...
        # df['funding_rate_ma'] = df['funding_rate'].rolling(24).mean()
        return df

    @staticmethod
    def add_open_interest(df: pd.DataFrame) -> pd.DataFrame:
        """
        Open interest - total open positions
        YÃ¼ksek OI = gÃ¼Ã§lÃ¼ trend
        """
        # df['open_interest'] = ...
        # df['oi_change'] = df['open_interest'].pct_change()
        return df

    @staticmethod
    def add_liquidation_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        Liquidation data
        BÃ¼yÃ¼k liquidation'lar trend reversal sinyali
        """
        # df['long_liquidations'] = ...
        # df['short_liquidations'] = ...
        # df['liquidation_imbalance'] = long_liq - short_liq
        return df
```

#### B) Volatility Clustering (GARCH)

```python
from arch import arch_model

def add_garch_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    GARCH(1,1) volatility forecasting
    Volatility clustering pattern'leri yakala
    """
    returns = df['close'].pct_change().dropna() * 100

    # Fit GARCH(1,1)
    model = arch_model(returns, vol='Garch', p=1, q=1)
    fitted = model.fit(disp='off')

    # Conditional volatility forecast
    df['garch_volatility'] = fitted.conditional_volatility

    return df
```

#### C) Time-Based Features

```python
def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Temporal patterns
    """
    df['hour'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    df['day_of_month'] = df['timestamp'].dt.day
    df['month'] = df['timestamp'].dt.month

    # Cyclical encoding (sin/cos)
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)

    # Is weekend
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

    return df
```

#### D) Feature Interactions

```python
def add_feature_interactions(df: pd.DataFrame) -> pd.DataFrame:
    """
    Non-linear feature combinations
    """
    # Momentum Ã— Volume
    df['momentum_volume'] = df['roc_10'] * df['volume_zscore']

    # RSI Ã— Bollinger Band position
    df['rsi_bb'] = df['rsi_14'] * df['bb_position']

    # MACD Ã— Trend strength
    df['macd_trend'] = df['macd_histogram'] * df['trend_slope_norm']

    # Price distance Ã— Volume spike
    df['price_vol_interaction'] = df['vwap_distance'] * df['volume_spike']

    return df
```

---

### 5ï¸âƒ£ Ensemble Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: DÃœÅÃœK) ğŸ­

#### A) XGBoost Meta-Learner (Logistic Regression Yerine)

```python
# backend/ml/models/ensemble.py

from xgboost import XGBClassifier

class EnsembleMetaLearner:
    def __init__(self, ..., meta_model_type='xgboost'):
        ...

        if meta_model_type == 'xgboost':
            self.meta_model = XGBClassifier(
                n_estimators=100,
                max_depth=3,
                learning_rate=0.1,
                random_state=42
            )
        elif meta_model_type == 'logistic':
            self.meta_model = LogisticRegression(...)
```

#### B) Weighted Averaging (Basit ama Etkili)

```python
def predict_weighted(self, X):
    """
    Weighted average of base models
    Weights based on validation performance
    """
    lgb_pred = self.lgb_model.predict_proba(X)
    xgb_pred = self.xgb_model.predict_direction_proba(X)

    # Weights based on F1 scores
    lgb_weight = 0.35  # F1: 0.70
    xgb_weight = 0.45  # Direction accuracy: 0.70
    lstm_weight = 0.20  # F1: 0.54 (zayÄ±f)

    ensemble_proba = (
        lgb_weight * lgb_pred +
        xgb_weight * xgb_pred +
        lstm_weight * lstm_pred
    )

    return np.argmax(ensemble_proba, axis=1)
```

#### C) Multi-Level Stacking

```python
# Level 1: Base models (LGB, XGB, LSTM)
# Level 2: Meta-learner 1 (XGBoost)
# Level 3: Meta-learner 2 (Logistic Regression)

# Daha derin ensemble, daha iyi generalization
```

---

### 6ï¸âƒ£ Data Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: ORTA) ğŸ’¾

#### A) Daha Fazla Coin Ekle

```python
# train_ml.py
symbols = [
    'BTCUSDT', 'ETHUSDT', 'BNBUSDT',
    'SOLUSDT', 'ADAUSDT', 'DOGEUSDT',  # â† Yeni coinler
    'MATICUSDT', 'AVAXUSDT'
]

# Daha diverse dataset = daha iyi generalization
```

#### B) Multi-Timeframe Learning

```python
# FarklÄ± timeframe'lerden eÄŸit
intervals = ['15m', '1h', '4h']

# Her timeframe iÃ§in ayrÄ± model
# Veya hepsini birleÅŸtir (feature olarak timeframe bilgisi ekle)
```

#### C) Data Augmentation

```python
def augment_timeseries(X, y, augmentation_factor=2):
    """
    Time series data augmentation
    """
    X_aug, y_aug = [], []

    for i in range(augmentation_factor):
        # Jittering (noise)
        noise = np.random.normal(0, 0.01, X.shape)
        X_noisy = X + noise

        # Window slicing
        start_idx = np.random.randint(0, 10)
        X_sliced = X[start_idx:]
        y_sliced = y[start_idx:]

        X_aug.extend([X_noisy, X_sliced])
        y_aug.extend([y, y_sliced])

    return np.concatenate(X_aug), np.concatenate(y_aug)
```

---

### 7ï¸âƒ£ Training Strategy Ä°yileÅŸtirmeleri (Ã–NCELÄ°K: DÃœÅÃœK) ğŸ“ˆ

#### A) Walk-Forward Validation

```python
def walk_forward_validation(df, window_size=1000, step_size=100):
    """
    Rolling window training
    Her ay yeni data ile re-train
    """
    results = []

    for i in range(0, len(df) - window_size, step_size):
        # Train window
        train_df = df[i:i+window_size]

        # Test window
        test_df = df[i+window_size:i+window_size+step_size]

        # Train model
        model = train_model(train_df)

        # Evaluate
        metrics = evaluate(model, test_df)
        results.append(metrics)

    return results
```

#### B) Time Series Cross-Validation

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    # Train and evaluate
    ...
```

---

## ğŸ“‹ Ã–ncelikli Ä°yileÅŸtirme PlanÄ± (SÄ±ralÄ±)

### âš¡ AÅŸama 1: HÄ±zlÄ± KazanÃ§lar (1-2 gÃ¼n)
1. âœ… **Label threshold'u artÄ±r** (0.002 â†’ 0.005)
2. âœ… **Hyperparameter optimization aÃ§** (optimize_hyperparams=True)
3. âœ… **LSTM class weighting ekle**
4. âœ… **Daha fazla coin ekle** (3 â†’ 8 coin)

**Beklenen Ä°yileÅŸme:**
- Ensemble: 63% â†’ 68%
- LSTM: 43% â†’ 50%

---

### ğŸš€ AÅŸama 2: Orta Seviye Ä°yileÅŸtirmeler (3-5 gÃ¼n)
1. âœ… **Adaptive threshold** (volatility-based)
2. âœ… **LSTM architecture** (Bidirectional + Attention)
3. âœ… **Feature interactions** ekle
4. âœ… **Time-based features** ekle
5. âœ… **Sequence length artÄ±r** (50 â†’ 100)

**Beklenen Ä°yileÅŸme:**
- Ensemble: 68% â†’ 72%
- LSTM: 50% â†’ 58%

---

### ğŸ¯ AÅŸama 3: Advanced Ä°yileÅŸtirmeler (1-2 hafta)
1. âœ… **Multi-horizon labels**
2. âœ… **GARCH volatility features**
3. âœ… **Market microstructure** (funding rate, OI)
4. âœ… **XGBoost meta-learner**
5. âœ… **Data augmentation**
6. âœ… **Walk-forward validation**

**Beklenen Ä°yileÅŸme:**
- Ensemble: 72% â†’ 75%+
- LSTM: 58% â†’ 62%+

---

## ğŸ¯ Hedef Performans

### KÄ±sa Vadeli Hedefler (1 ay):
- **LightGBM**: 64% â†’ **70%** accuracy
- **XGBoost**: RÂ²=0.18 â†’ **0.25+** (direction accuracy zaten iyi: 70%)
- **LSTM**: 43% â†’ **60%** accuracy
- **Ensemble**: 63% â†’ **72%** accuracy

### Orta Vadeli Hedefler (3 ay):
- **Ensemble**: **75%+** accuracy
- **Sharpe Ratio**: **1.5+** (backtest)
- **Win Rate**: **55-60%**
- **Profit Factor**: **1.8+**

### Uzun Vadeli Hedefler (6+ ay):
- **Ensemble**: **78%+** accuracy
- **Multi-asset** trading (10+ coins)
- **Multi-timeframe** strategy
- **Live trading** with adaptive re-training

---

## ğŸ“Š Ä°yileÅŸtirme Takibi

Her iyileÅŸtirmeden sonra bu metrikleri kaydet:

```python
metrics_to_track = {
    'accuracy': ...,
    'precision_macro': ...,
    'recall_macro': ...,
    'f1_macro': ...,
    'per_class_f1': {
        'SELL': ...,
        'HOLD': ...,
        'BUY': ...
    },
    'confusion_matrix': ...,
    'training_time': ...,
    'inference_time': ...
}
```

**KarÅŸÄ±laÅŸtÄ±rma iÃ§in:**
- Baseline (current): `registry.json` iÃ§indeki production models
- Her iyileÅŸtirme: Yeni version olarak kaydet
- A/B test: Production'da 50/50 split test

---

## ğŸ”§ Kod DeÄŸiÅŸiklik Ã–nerileri

### Ã–ncelik 1: LSTM Class Weighting
**Dosya**: `backend/ml/models/lstm_model.py`
**SatÄ±r**: ~100 (loss function tanÄ±mÄ±)

```python
# Ã–nce
self.criterion = nn.CrossEntropyLoss()

# Sonra
class_weights = torch.tensor([1.5, 2.0, 1.0])  # SELL, HOLD, BUY
self.criterion = nn.CrossEntropyLoss(weight=class_weights.to(self.device))
```

---

### Ã–ncelik 2: Label Threshold ArtÄ±rma
**Dosya**: `backend/ml/data/labels.py`
**SatÄ±r**: 46

```python
# Ã–nce
def create_direction_label(self, periods=5, threshold=0.002) -> pd.DataFrame:

# Sonra
def create_direction_label(self, periods=5, threshold=0.005) -> pd.DataFrame:
```

---

### Ã–ncelik 3: Hyperparameter Optimization
**Dosya**: `backend/train_ml.py`
**SatÄ±r**: 477

```python
# Ã–nce
optimize_hyperparams=False,

# Sonra
optimize_hyperparams=True,
```

---

### Ã–ncelik 4: Daha Fazla Coin
**Dosya**: `backend/train_ml.py`
**SatÄ±r**: 474

```python
# Ã–nce
symbols=['BTCUSDT', 'ETHUSDT', 'BNBUSDT'],

# Sonra
symbols=['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'ADAUSDT', 'DOGEUSDT'],
```

---

## ğŸ“š Ek Kaynaklar

- [Time Series Classification with Deep Learning](https://arxiv.org/abs/1809.04356)
- [Financial Time Series Forecasting with LSTM](https://www.sciencedirect.com/science/article/pii/S0957417420308381)
- [Ensemble Methods for Financial Trading](https://www.mdpi.com/2227-9091/9/1/16)
- [Hyperparameter Optimization with Optuna](https://optuna.readthedocs.io/)

---

## âœ… Checklist

### Hemen YapÄ±lacaklar:
- [ ] Label threshold artÄ±r (0.002 â†’ 0.005)
- [ ] Hyperparameter optimization aÃ§
- [ ] LSTM class weighting ekle
- [ ] Daha fazla coin ekle

### Sonraki AdÄ±mlar:
- [ ] Adaptive threshold implement et
- [ ] LSTM Bidirectional + Attention
- [ ] Feature interactions ekle
- [ ] Time-based features ekle

### Uzun Vadeli:
- [ ] Multi-horizon labels
- [ ] GARCH volatility features
- [ ] Market microstructure features
- [ ] Walk-forward validation
- [ ] Live trading setup

---

## ğŸ†• Yeni Ã–zellikler: Coin BazlÄ± ML Sistemi

### 8ï¸âƒ£ Coin-Specific Model Training (Ã–NCELÄ°K: YÃœKSEK) ğŸª™

#### Sorun:
Åu an tÃ¼m coinler iÃ§in tek bir model eÄŸitiliyor. Ama her coin'in kendine Ã¶zgÃ¼ davranÄ±ÅŸlarÄ± var:
- BTC: Daha az volatil, trend following
- ETH: BTC'yi takip eder ama kendi dinamikleri var
- Altcoinler: Ã‡ok volatil, momentum-based

**Tek model yaklaÅŸÄ±mÄ±:** GenelleÅŸtirir ama spesifik pattern'leri kaÃ§Ä±rÄ±r.

#### Ã‡Ã¶zÃ¼m: Coin-Specific Models + Universal Model

**A) Her Coin Ä°Ã§in AyrÄ± Model EÄŸit**

```python
# backend/train_coin_specific_models.py (YENÄ° DOSYA)

class CoinSpecificTrainer:
    """
    Her coin iÃ§in ayrÄ± model eÄŸit
    Coin-specific pattern'leri daha iyi yakala
    """

    def __init__(self, symbols: list):
        self.symbols = symbols
        self.models = {}

    async def train_all_coins(self):
        """Her coin iÃ§in ayrÄ± ayrÄ± model eÄŸit"""
        for symbol in self.symbols:
            logger.info(f"Training models for {symbol}...")

            # Her coin iÃ§in ayrÄ± pipeline
            pipeline = MLTrainingPipeline(
                symbols=[symbol],  # Tek coin
                interval='1h',
                future_periods=5,
                optimize_hyperparams=True,
                train_ensemble=True
            )

            await pipeline.run()

            # Model'i kaydet
            self.models[symbol] = {
                'lgbm': pipeline.lgb_model,
                'xgb': pipeline.xgb_model,
                'ensemble': pipeline.ensemble_model
            }

        logger.info(f"Trained models for {len(self.symbols)} coins")

# KullanÄ±m:
trainer = CoinSpecificTrainer(['BTCUSDT', 'ETHUSDT', 'BNBUSDT'])
await trainer.train_all_coins()
```

**B) Universal Model + Coin Embeddings**

```python
# Her coin iÃ§in embedding vektÃ¶rÃ¼
coin_embeddings = {
    'BTCUSDT': [1.0, 0.0, 0.0],  # Major coin, low vol
    'ETHUSDT': [0.8, 0.2, 0.0],  # Major coin, medium vol
    'BNBUSDT': [0.5, 0.3, 0.2],  # Exchange token
    'SOLUSDT': [0.2, 0.5, 0.3],  # Altcoin, high vol
}

# Feature'lara coin embedding ekle
def add_coin_features(df: pd.DataFrame) -> pd.DataFrame:
    """Coin-specific features"""

    # Coin embedding
    for i, val in enumerate(coin_embeddings[df['symbol'].iloc[0]]):
        df[f'coin_embed_{i}'] = val

    # Coin category (one-hot)
    df['is_major'] = (df['symbol'].isin(['BTCUSDT', 'ETHUSDT'])).astype(int)
    df['is_altcoin'] = (~df['symbol'].isin(['BTCUSDT', 'ETHUSDT'])).astype(int)

    return df
```

**C) Hybrid: Universal Model + Fine-tuning**

```python
# 1. Universal model'i tÃ¼m coinlerle eÄŸit
universal_model = train_on_all_coins()

# 2. Her coin iÃ§in fine-tune yap
for symbol in symbols:
    coin_model = universal_model.copy()
    coin_model.fine_tune(symbol_data=data[symbol], epochs=10)
    save_model(coin_model, f"models/{symbol}_finetuned.pkl")
```

---

### 9ï¸âƒ£ Automated Coin Addition System (Ã–NCELÄ°K: ORTA) ğŸ¤–

#### Senaryo:
Yeni bir coin eklemek istiyorsun (Ã¶rn: AVAXUSDT). Manuel olarak:
1. Historical data indir
2. Feature'larÄ± hesapla
3. Model'i yeniden eÄŸit
4. Test et

**Ã‡ok zahmetli!**

#### Ã‡Ã¶zÃ¼m: Otomatik Coin Ekleme Scripti

```python
# backend/add_new_coin.py (YENÄ° DOSYA)

"""
Otomatik olarak yeni coin ekle ve model eÄŸit
"""

import asyncio
import argparse
from download_historical_data import download_symbol_data
from calculate_features import FeatureCalculator
from train_ml import MLTrainingPipeline

class CoinAdder:
    """
    Yeni coin eklemek iÃ§in all-in-one script
    """

    def __init__(self, symbol: str, interval: str = '1h'):
        self.symbol = symbol
        self.interval = interval

    async def add_coin(self, train_model: bool = True):
        """
        Yeni coin'i sisteme ekle

        Args:
            train_model: True ise model'i yeniden eÄŸit
        """

        print(f"\n{'='*60}")
        print(f"ğŸª™ Adding new coin: {self.symbol}")
        print(f"{'='*60}\n")

        # 1. Historical data indir
        print("ğŸ“¥ Step 1/4: Downloading historical data...")
        await self.download_historical_data()
        print("âœ… Historical data downloaded")

        # 2. Feature'larÄ± hesapla
        print("\nğŸ“Š Step 2/4: Calculating features...")
        await self.calculate_features()
        print("âœ… Features calculated")

        # 3. Config'e ekle
        print("\nâš™ï¸  Step 3/4: Updating config...")
        self.add_to_config()
        print("âœ… Config updated")

        # 4. Model'i eÄŸit (opsiyonel)
        if train_model:
            print("\nğŸ¤– Step 4/4: Training ML model...")
            await self.train_model()
            print("âœ… Model trained")
        else:
            print("\nâ­ï¸  Step 4/4: Skipping model training")

        print(f"\n{'='*60}")
        print(f"âœ… Successfully added {self.symbol}!")
        print(f"{'='*60}\n")

    async def download_historical_data(self):
        """Historical data indir"""
        from download_historical_data import download_symbol_data

        await download_symbol_data(
            symbol=self.symbol,
            interval=self.interval,
            start_date='2024-01-01',  # Son 1 yÄ±l
            limit=1000  # Yeterli veri
        )

    async def calculate_features(self):
        """Feature'larÄ± hesapla"""
        from calculate_features import FeatureCalculator

        calculator = FeatureCalculator()
        await calculator.calculate_symbol_features(
            symbol=self.symbol,
            interval=self.interval
        )

    def add_to_config(self):
        """Config dosyasÄ±na ekle"""
        import json

        # .env dosyasÄ±nÄ± gÃ¼ncelle
        with open('.env', 'a') as f:
            current_symbols = os.getenv('BINANCE_SYMBOLS', '')
            if self.symbol not in current_symbols:
                new_symbols = f"{current_symbols},{self.symbol}"
                f.write(f"\nBINANCE_SYMBOLS={new_symbols}\n")

    async def train_model(self):
        """Model'i yeniden eÄŸit (yeni coin ile)"""

        # TÃ¼m coinleri al
        all_symbols = os.getenv('BINANCE_SYMBOLS').split(',')

        # Yeni coin dahil tÃ¼m coinlerle eÄŸit
        pipeline = MLTrainingPipeline(
            symbols=all_symbols,
            interval=self.interval,
            future_periods=5,
            optimize_hyperparams=False,  # Ä°lk eÄŸitim hÄ±zlÄ± olsun
            train_ensemble=True
        )

        await pipeline.run()


# CLI kullanÄ±mÄ±
async def main():
    parser = argparse.ArgumentParser(description='Add new coin to the system')
    parser.add_argument('symbol', type=str, help='Symbol to add (e.g., AVAXUSDT)')
    parser.add_argument('--interval', type=str, default='1h', help='Timeframe')
    parser.add_argument('--no-train', action='store_true', help='Skip model training')

    args = parser.parse_args()

    adder = CoinAdder(args.symbol, args.interval)
    await adder.add_coin(train_model=not args.no_train)


if __name__ == "__main__":
    asyncio.run(main())
```

**KullanÄ±m:**

```bash
# AVAXUSDT coin'ini ekle (data indir + feature hesapla + model eÄŸit)
python backend/add_new_coin.py AVAXUSDT

# Sadece data indir + feature hesapla (model eÄŸitme)
python backend/add_new_coin.py AVAXUSDT --no-train

# FarklÄ± interval
python backend/add_new_coin.py SOLUSDT --interval 4h
```

**Ã‡Ä±ktÄ±:**
```
============================================================
ğŸª™ Adding new coin: AVAXUSDT
============================================================

ğŸ“¥ Step 1/4: Downloading historical data...
   Downloaded 8760 candles (365 days)
âœ… Historical data downloaded

ğŸ“Š Step 2/4: Calculating features...
   Calculated 120 features
âœ… Features calculated

âš™ï¸  Step 3/4: Updating config...
âœ… Config updated

ğŸ¤– Step 4/4: Training ML model...
   Training with 4 coins: BTCUSDT, ETHUSDT, BNBUSDT, AVAXUSDT
   Ensemble accuracy: 68.4%
âœ… Model trained

============================================================
âœ… Successfully added AVAXUSDT!
============================================================
```

---

### ğŸ”Ÿ Batch Coin Addition (Ã–NCELÄ°K: DÃœÅÃœK) ğŸ“¦

**Senaryo:** Birden fazla coin eklemek istiyorsun.

```python
# backend/add_multiple_coins.py (YENÄ° DOSYA)

"""
Birden fazla coin'i toplu ekle
"""

class BatchCoinAdder:
    """Toplu coin ekleme"""

    def __init__(self, symbols: list, interval: str = '1h'):
        self.symbols = symbols
        self.interval = interval

    async def add_all_coins(self):
        """TÃ¼m coinleri ekle"""

        print(f"\n{'='*60}")
        print(f"ğŸª™ Adding {len(self.symbols)} coins...")
        print(f"{'='*60}\n")

        for i, symbol in enumerate(self.symbols, 1):
            print(f"\n[{i}/{len(self.symbols)}] Processing {symbol}...")

            adder = CoinAdder(symbol, self.interval)
            await adder.add_coin(train_model=False)  # Son coin dÄ±ÅŸÄ±nda model eÄŸitme

        # Son olarak tÃ¼m coinlerle birlikte model eÄŸit
        print(f"\nğŸ¤– Training model with all {len(self.symbols)} coins...")
        await self.train_all()

        print(f"\n{'='*60}")
        print(f"âœ… Successfully added {len(self.symbols)} coins!")
        print(f"{'='*60}\n")

    async def train_all(self):
        """TÃ¼m coinlerle model eÄŸit"""
        all_symbols = os.getenv('BINANCE_SYMBOLS').split(',')

        pipeline = MLTrainingPipeline(
            symbols=all_symbols,
            interval=self.interval,
            optimize_hyperparams=True,  # Son eÄŸitim optimize edilsin
            train_ensemble=True
        )

        await pipeline.run()


# KullanÄ±m
async def main():
    new_coins = ['AVAXUSDT', 'SOLUSDT', 'MATICUSDT', 'DOGEUSDT']

    batch_adder = BatchCoinAdder(new_coins)
    await batch_adder.add_all_coins()


if __name__ == "__main__":
    asyncio.run(main())
```

**KullanÄ±m:**

```bash
# Birden fazla coin ekle
python backend/add_multiple_coins.py
```

---

### 1ï¸âƒ£1ï¸âƒ£ Model Versioning & Rollback (Ã–NCELÄ°K: ORTA) ğŸ”„

**Senaryo:** Yeni model eÄŸittin ama eskisinden kÃ¶tÃ¼. Ã–nceki versiyona geri dÃ¶nmek istiyorsun.

```python
# Model registry zaten var, sadece rollback fonksiyonu ekle

# backend/ml/utils/model_registry.py

class ModelRegistry:
    # ... mevcut kod ...

    def rollback_to_version(self, model_name: str, version: str):
        """
        Belirli bir versiyona geri dÃ¶n

        Args:
            model_name: Model adÄ± (e.g., 'ensemble')
            version: Version (e.g., 'v_20251010_203136')
        """
        if model_name not in self.metadata['models']:
            raise ValueError(f"Model {model_name} not found")

        if version not in self.metadata['models'][model_name]['versions']:
            raise ValueError(f"Version {version} not found")

        # Eski production'Ä± archive yap
        old_prod = self.metadata['models'][model_name].get('production_version')
        if old_prod:
            self.metadata['models'][model_name]['versions'][old_prod]['status'] = 'archived'

        # Yeni versiyonu production yap
        self.metadata['models'][model_name]['production_version'] = version
        self.metadata['models'][model_name]['versions'][version]['status'] = 'production'

        self._save_metadata()

        logger.info(f"Rolled back {model_name} to version {version}")

    def compare_versions(self, model_name: str, v1: str, v2: str) -> dict:
        """
        Ä°ki versiyonu karÅŸÄ±laÅŸtÄ±r
        """
        m1 = self.metadata['models'][model_name]['versions'][v1]
        m2 = self.metadata['models'][model_name]['versions'][v2]

        comparison = {
            'v1': v1,
            'v2': v2,
            'metrics_diff': {}
        }

        # Metrikleri karÅŸÄ±laÅŸtÄ±r
        for metric in m1['metrics']:
            if metric in m2['metrics']:
                diff = m2['metrics'][metric] - m1['metrics'][metric]
                comparison['metrics_diff'][metric] = {
                    'v1': m1['metrics'][metric],
                    'v2': m2['metrics'][metric],
                    'diff': diff,
                    'percent_change': (diff / m1['metrics'][metric]) * 100 if m1['metrics'][metric] != 0 else 0
                }

        return comparison
```

**KullanÄ±m:**

```bash
# Model versiyonlarÄ±nÄ± listele
python -c "
from backend.ml.utils.model_registry import ModelRegistry
registry = ModelRegistry()
print(registry.list_models())
"

# Ã–nceki versiyona geri dÃ¶n
python -c "
from backend.ml.utils.model_registry import ModelRegistry
registry = ModelRegistry()
registry.rollback_to_version('ensemble', 'v_20251010_201738')
"
```

---

### 1ï¸âƒ£2ï¸âƒ£ Automated Retraining Schedule (Ã–NCELÄ°K: DÃœÅÃœK) â°

**Senaryo:** Her hafta otomatik olarak modeli yeniden eÄŸitmek istiyorsun.

```python
# backend/scheduled_training.py (YENÄ° DOSYA)

"""
Otomatik periyodik model eÄŸitimi
"""

import schedule
import time
import asyncio

class ScheduledTrainer:
    """
    Belirli aralÄ±klarla otomatik model eÄŸitimi
    """

    def __init__(self, interval: str = 'weekly'):
        self.interval = interval

    async def train_job(self):
        """EÄŸitim gÃ¶revi"""
        logger.info("Starting scheduled training...")

        pipeline = MLTrainingPipeline(
            symbols=settings.get_symbols(),
            interval='1h',
            optimize_hyperparams=True,
            train_ensemble=True
        )

        await pipeline.run()

        logger.info("Scheduled training completed")

    def start(self):
        """Scheduler'Ä± baÅŸlat"""

        if self.interval == 'daily':
            # Her gÃ¼n 02:00'de Ã§alÄ±ÅŸ
            schedule.every().day.at("02:00").do(
                lambda: asyncio.run(self.train_job())
            )
        elif self.interval == 'weekly':
            # Her pazar 02:00'de Ã§alÄ±ÅŸ
            schedule.every().sunday.at("02:00").do(
                lambda: asyncio.run(self.train_job())
            )
        elif self.interval == 'monthly':
            # Her ayÄ±n 1'i 02:00'de Ã§alÄ±ÅŸ
            schedule.every().month.at("02:00").do(
                lambda: asyncio.run(self.train_job())
            )

        logger.info(f"Scheduled training: {self.interval}")

        # SÃ¼rekli Ã§alÄ±ÅŸ
        while True:
            schedule.run_pending()
            time.sleep(60)  # Her dakika kontrol et


# KullanÄ±m
if __name__ == "__main__":
    trainer = ScheduledTrainer(interval='weekly')
    trainer.start()
```

**Systemd service olarak Ã§alÄ±ÅŸtÄ±r (Linux):**

```bash
# /etc/systemd/system/ml-trainer.service
[Unit]
Description=ML Scheduled Training
After=network.target

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/crypto-ai-agent
ExecStart=/path/to/venv/bin/python backend/scheduled_training.py
Restart=always

[Install]
WantedBy=multi-user.target
```

---

## ğŸ“‹ GÃ¼ncellenmiÅŸ Ã–ncelik Listesi

### âš¡ AÅŸama 1: HÄ±zlÄ± KazanÃ§lar (2-3 gÃ¼n) - HEMEN BAÅLA
1. âœ… **Label threshold artÄ±r** (0.002 â†’ 0.005)
2. âœ… **Hyperparameter optimization aÃ§**
3. âœ… **Daha fazla coin ekle** (3 â†’ 6-8 coin)
4. âœ… **LSTM class weighting**

**Beklenen:** 64% â†’ 68-70% accuracy

---

### ğŸš€ AÅŸama 2: Coin-Specific Improvements (3-5 gÃ¼n)
1. âœ… **Coin embedding features** ekle
2. âœ… **Otomatik coin ekleme scripti** (`add_new_coin.py`)
3. âœ… **Model versioning & rollback** sistemi
4. âœ… **Adaptive threshold** (volatility-based)

**Beklenen:** 68% â†’ 72% accuracy

---

### ğŸ¯ AÅŸama 3: Advanced Features (1-2 hafta)
1. âœ… **Coin-specific model training**
2. âœ… **Batch coin addition**
3. âœ… **Time-based features**
4. âœ… **Feature interactions**
5. âœ… **LSTM Bidirectional + Attention**

**Beklenen:** 72% â†’ 75%+ accuracy

---

## ğŸ› ï¸ Ä°lk AdÄ±mlar (Åimdi YapÄ±lacaklar)

### 1. Quick Wins (1 saat kod, 2-3 gÃ¼n eÄŸitim)

```bash
# 1. Label threshold artÄ±r
# backend/ml/data/labels.py:46
threshold=0.005  # 0.002 â†’ 0.005

# 2. Hyperparameter optimization aÃ§
# backend/train_ml.py:477
optimize_hyperparams=True

# 3. Daha fazla coin ekle
# backend/train_ml.py:474
symbols=['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'ADAUSDT', 'DOGEUSDT']

# 4. Model'i eÄŸit
python backend/train_ml.py
```

### 2. Yeni Coin Ekleme Scripti (2-3 saat)

```bash
# add_new_coin.py scriptini oluÅŸtur
# KullanÄ±m:
python backend/add_new_coin.py AVAXUSDT
```

### 3. Model Versioning (1 saat)

```python
# ModelRegistry'ye rollback ve compare fonksiyonlarÄ± ekle
registry.rollback_to_version('ensemble', 'v_20251010_201738')
registry.compare_versions('ensemble', 'v1', 'v2')
```

---

**Son GÃ¼ncelleme**: 2025-10-12
**Versiyon**: 2.0
**Sorumlu**: Crypto AI Trading Team

---

## ğŸ¯ Sonraki 1 Hafta Roadmap

**GÃ¼n 1-2:** Quick wins implementation
- Label threshold + hyperparams + more coins
- Re-train models
- **Hedef:** 68% accuracy

**GÃ¼n 3-4:** Coin-specific features
- add_new_coin.py script
- Coin embeddings
- Test with 2-3 new coins

**GÃ¼n 5-7:** Advanced improvements
- Adaptive threshold
- LSTM improvements
- Model versioning
- **Hedef:** 72% accuracy

**Hafta Sonu:** Test & evaluate
- Backtest all models
- Compare metrics
- Document results
